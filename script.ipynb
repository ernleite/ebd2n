{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7dc16-2d5a-4cd6-afa6-432b7b9dbad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ignite numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2c937a-a13c-429f-aff0-2426eff2b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-25 13:42:04,339 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'gloo'\n",
      "2025-06-25 13:42:04,340 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: \n",
      "\tnproc_per_node: 1\n",
      "\tnnodes: 2\n",
      "\tnode_rank: 0\n",
      "\tmaster_addr: 192.168.1.191\n",
      "\tmaster_port: 29500\n",
      "2025-06-25 13:42:04,340 ignite.distributed.launcher.Parallel INFO: Spawn function '<function train_fn at 0x740fb16a3ce0>' in 1 processes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     32\u001b[0m dist_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnproc_per_node\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,        \u001b[38;5;66;03m# 1 process per machine\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,                 \u001b[38;5;66;03m# Total machines\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaster_port\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m29500\u001b[39m          \u001b[38;5;66;03m# Open port on master\u001b[39;00m\n\u001b[1;32m     38\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m idist\u001b[38;5;241m.\u001b[39mParallel(backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgloo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdist_config) \u001b[38;5;28;01mas\u001b[39;00m parallel:\n\u001b[0;32m---> 41\u001b[0m     parallel\u001b[38;5;241m.\u001b[39mrun(train_fn)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     44\u001b[0m     freeze_support()\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/ignite/distributed/launcher.py:312\u001b[0m, in \u001b[0;36mParallel.run\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spawn_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawn function \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spawn_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnproc_per_node\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m     )\n\u001b[0;32m--> 312\u001b[0m     idist\u001b[38;5;241m.\u001b[39mspawn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend, func, args\u001b[38;5;241m=\u001b[39margs, kwargs_dict\u001b[38;5;241m=\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spawn_params)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Run \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midist\u001b[38;5;241m.\u001b[39mget_world_size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/ignite/distributed/utils.py:324\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(backend, fn, args, kwargs_dict, nproc_per_node, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m comp_model_cls\u001b[38;5;241m.\u001b[39mavailable_backends:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m comp_model_cls\u001b[38;5;241m.\u001b[39mspawn(\n\u001b[1;32m    325\u001b[0m     fn, args\u001b[38;5;241m=\u001b[39margs, kwargs_dict\u001b[38;5;241m=\u001b[39mkwargs_dict, nproc_per_node\u001b[38;5;241m=\u001b[39mnproc_per_node, backend\u001b[38;5;241m=\u001b[39mbackend, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    326\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/ignite/distributed/comp_models/native.py:392\u001b[0m, in \u001b[0;36m_NativeDistModel.spawn\u001b[0;34m(fn, args, kwargs_dict, nproc_per_node, nnodes, node_rank, master_addr, master_port, backend, init_method, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m master_port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaster_port should be None if init_method is provided other then \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv://\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 392\u001b[0m start_processes(\n\u001b[1;32m    393\u001b[0m     _NativeDistModel\u001b[38;5;241m.\u001b[39m_dist_worker_task_fn,\n\u001b[1;32m    394\u001b[0m     nprocs\u001b[38;5;241m=\u001b[39mnproc_per_node,\n\u001b[1;32m    395\u001b[0m     args\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    396\u001b[0m         backend,\n\u001b[1;32m    397\u001b[0m         fn,\n\u001b[1;32m    398\u001b[0m         args,\n\u001b[1;32m    399\u001b[0m         kwargs_dict,\n\u001b[1;32m    400\u001b[0m         world_size,\n\u001b[1;32m    401\u001b[0m         nproc_per_node,\n\u001b[1;32m    402\u001b[0m         node_rank,\n\u001b[1;32m    403\u001b[0m         master_addr,\n\u001b[1;32m    404\u001b[0m         master_port,\n\u001b[1;32m    405\u001b[0m         init_method,\n\u001b[1;32m    406\u001b[0m         kwargs,\n\u001b[1;32m    407\u001b[0m     ),\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspawn_kwargs,\n\u001b[1;32m    409\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:237\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mjoin():\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:117\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Wait for any process to fail or all of them to succeed.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m ready \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mconnection\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinels\u001b[38;5;241m.\u001b[39mkeys(),\n\u001b[1;32m    119\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m error_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ignite.distributed as idist\n",
    "\n",
    "def train_fn(local_rank, matrix_size=100):\n",
    "    device = idist.device()\n",
    "    rank = idist.get_rank()\n",
    "    \n",
    "    # Master (rank 0) creates initial matrix\n",
    "    if rank == 0:\n",
    "        data = torch.randn(matrix_size, 1, device=device)\n",
    "    else:\n",
    "        data = torch.zeros(matrix_size, 1, device=device)\n",
    "    \n",
    "    # Broadcast full matrix to all nodes\n",
    "    data = idist.broadcast(data, src=0)\n",
    "    \n",
    "    # Split and process data\n",
    "    chunk_size = matrix_size // idist.get_world_size()\n",
    "    start_idx = rank * chunk_size\n",
    "    end_idx = (rank + 1) * chunk_size\n",
    "    local_data = data[start_idx:end_idx].clone()\n",
    "    local_data += torch.rand(1, device=device)  # Add random value\n",
    "    \n",
    "    # Gather results at master\n",
    "    gathered = idist.all_gather(local_data)\n",
    "    \n",
    "    if rank == 0:\n",
    "        result = torch.cat(gathered)[:matrix_size]  # Combine slices\n",
    "        print(\"Final result:\\n\", result)\n",
    "\n",
    "# Distributed configuration (MUST be set per node)\n",
    "dist_config = {\n",
    "    \"nproc_per_node\": 1,        # 1 process per machine\n",
    "    \"nnodes\": 2,                 # Total machines\n",
    "    \"node_rank\": 0,              # 0 for master, 1 for worker\n",
    "    \"master_addr\": \"192.168.1.191\", # Master node IP\n",
    "    \"master_port\": 29500          # Open port on master\n",
    "}\n",
    "\n",
    "with idist.Parallel(backend=\"gloo\", **dist_config) as parallel:\n",
    "    parallel.run(train_fn)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9372e61-af3d-4c22-bfa0-ec0370582149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
